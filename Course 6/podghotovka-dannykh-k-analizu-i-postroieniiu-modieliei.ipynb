{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Неделя 1. Подготовка данных к анализу и построению моделей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPython 3.7.0\n",
      "IPython 7.0.1\n",
      "\n",
      "numpy 1.15.3\n",
      "scipy 1.1.0\n",
      "pandas 0.23.4\n",
      "matplotlib 3.0.1\n",
      "statsmodels 0.9.0\n",
      "sklearn 0.20.0\n",
      "\n",
      "compiler   : Clang 6.0 (clang-600.0.57)\n",
      "system     : Darwin\n",
      "release    : 18.0.0\n",
      "machine    : x86_64\n",
      "processor  : i386\n",
      "CPU cores  : 8\n",
      "interpreter: 64bit\n",
      "Git hash   : 6c444d24686d4f3351c0b8133d243f3f12a577bb\n"
     ]
    }
   ],
   "source": [
    "%reload_ext watermark\n",
    "%watermark -v -m -p numpy,scipy,pandas,matplotlib,statsmodels,sklearn -g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pickle\n",
    "import string\n",
    "from collections import Counter, defaultdict\n",
    "from functools import partial\n",
    "from itertools import chain, count, zip_longest\n",
    "from pathlib import Path\n",
    "from typing import Any, Dict, List, Tuple\n",
    "\n",
    "import numpy\n",
    "import pandas\n",
    "from more_itertools import chunked, sliced\n",
    "from pandas import DataFrame\n",
    "from scipy.sparse import csr_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на один из файлов с данными о посещенных пользователем (номер 31) веб-страницах:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_frame_31 = pandas.read_csv(Path('10users') / 'user0031.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>site</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-11-15 08:12:07</td>\n",
       "      <td>fpdownload2.macromedia.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-11-15 08:12:17</td>\n",
       "      <td>laposte.net</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-11-15 08:12:17</td>\n",
       "      <td>www.laposte.net</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-11-15 08:12:17</td>\n",
       "      <td>www.google.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-11-15 08:12:18</td>\n",
       "      <td>www.laposte.net</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             timestamp                        site\n",
       "0  2013-11-15 08:12:07  fpdownload2.macromedia.com\n",
       "1  2013-11-15 08:12:17                 laposte.net\n",
       "2  2013-11-15 08:12:17             www.laposte.net\n",
       "3  2013-11-15 08:12:17              www.google.com\n",
       "4  2013-11-15 08:12:18             www.laposte.net"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_frame_31.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поставим задачу классификации: идентифицировать пользователя по сессии из 10 подряд посещенных сайтов. Объектом в этой задаче будет сессия из 10 сайтов, последовательно посещенных одним и тем же пользователем, признаками – индексы этих 10 сайтов (чуть позже здесь появится \"мешок\" сайтов, подход Bag of Words). Целевым классом будет id пользователя."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Часть 1. Подготовка обучающей выборки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реализуйте функцию `prepare_train_set`, которая принимает на вход путь к каталогу с CSV-файлами `path_to_csv_files` и параметр `session_length` – длину сессии, а возвращает 2 объекта:\n",
    "\n",
    "* `DataFrame`, в котором строки соответствуют уникальным сессиям из `session_length` сайтов, `session_length` столбцов – индексам этих `session_length` сайтов и последний столбец – ID пользователя\n",
    "* частотный словарь сайтов вида `{'site_string': [site_id, site_freq]}`, например для недавнего игрушечного примера это будет `{'vk.com': (1, 2), 'google.com': (2, 2), 'yandex.ru': (3, 3), 'facebook.com': (4, 1)}`\n",
    "\n",
    "Детали:\n",
    "\n",
    "* Смотрите чуть ниже пример вывода, что должна возвращать функция\n",
    "* Используйте `glob` (или аналоги) для обхода файлов в каталоге. Для определенности, отсортируйте список файлов лексикографически. Удобно использовать `tqdm_notebook` (или просто `tqdm` в случае python-скрипта) для отслеживания числа выполненных итераций цикла\n",
    "* Создайте частотный словарь уникальных сайтов (вида `{'site_string': (site_id, site_freq)}`) и заполняйте его по ходу чтения файлов. Начните с 1\n",
    "* Рекомендуется меньшие индексы давать более часто попадающимся сайтам (приницип наименьшего описания)\n",
    "* Не делайте entity recognition, считайте google.com, http://www.google.com и www.google.com разными сайтами (подключить entity recognition можно уже в рамках индивидуальной работы над проектом)\n",
    "* Скорее всего в файле число записей не кратно числу `session_length`. Тогда последняя сессия будет короче. Остаток заполняйте нулями. То есть если в файле 24 записи и сессии длины 10, то 3 сессия будет состоять из 4 сайтов, и ей мы сопоставим вектор `[site1_id, site2_id, site3_id, site4_id, 0, 0, 0, 0, 0, 0, user_id]`\n",
    "* В итоге некоторые сессии могут повторяться – оставьте как есть, не удаляйте дубликаты. Если в двух сессиях все сайты одинаковы, но сессии принадлежат разным пользователям, то тоже оставляйте как есть, это естественная неопределенность в данных\n",
    "* Не оставляйте в частотном словаре сайт 0 (уже в конце, когда функция возвращает этот словарь)\n",
    "* 150 файлов из `capstone_websites_data/150users/` у меня обработались за 1.7 секунды, но многое, конечно, зависит от реализации функции и от используемого железа. И вообще, первая реализация скорее всего будет не самой эффективной, дальше можно заняться профилированием (особенно если планируете запускать этот код для 3000 пользователей). Также эффективная реализация этой функции поможет нам на следующей неделе."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_train_set(path: Path, session_length: int = 10) -> Tuple[DataFrame, Dict[str, Tuple[int, int]]]:\n",
    "    # List of visited sites per each user.\n",
    "    user_sites: List[Tuple[int, List[str]]] = [\n",
    "        (int(csv_path.stem[-4:]), [row['site'] for row in csv.DictReader(csv_path.open('rt'))])\n",
    "        for csv_path in sorted(path.glob('*.csv'))\n",
    "    ]\n",
    "        \n",
    "    # Count visits per each site.\n",
    "    site_frequencies = Counter(chain.from_iterable(sites for _, sites in user_sites))\n",
    "    \n",
    "    # Assign an incremental ID to each unique site.\n",
    "    site_ids: Dict[str, int] = dict(zip(site_frequencies, count(start=1)))\n",
    "        \n",
    "    frame = DataFrame([\n",
    "        # User ID and each of `session_length` visited sites.\n",
    "        {'user_id': user_id, **{\n",
    "            # Assign `0` if session is too short.\n",
    "            f'site_{i:02d}': site_ids.get(site, 0)\n",
    "            for i, site in zip_longest(range(1, session_length + 1), session)\n",
    "        }}\n",
    "        for user_id, sites in user_sites\n",
    "        for session in sliced(sites, session_length)  # split user's sites into sessions\n",
    "    ], dtype=int)\n",
    "    frequency_dict = {\n",
    "        site: (site_id, site_frequencies[site]) \n",
    "        for site, site_id in site_ids.items()\n",
    "    }\n",
    "    return frame, frequency_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_3users, frequencies_3users = prepare_train_set(Path('3users'), session_length=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>site_01</th>\n",
       "      <th>site_02</th>\n",
       "      <th>site_03</th>\n",
       "      <th>site_04</th>\n",
       "      <th>site_05</th>\n",
       "      <th>site_06</th>\n",
       "      <th>site_07</th>\n",
       "      <th>site_08</th>\n",
       "      <th>site_09</th>\n",
       "      <th>site_10</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   site_01  site_02  site_03  site_04  site_05  site_06  site_07  site_08  \\\n",
       "0        1        2        2        3        2        4        5        6   \n",
       "1        1        4        4        4        0        0        0        0   \n",
       "2        1        2        9        9        2        0        0        0   \n",
       "3       10        4        2        4        2        4        4        6   \n",
       "4       10        4        2        0        0        0        0        0   \n",
       "\n",
       "   site_09  site_10  user_id  \n",
       "0        7        8        1  \n",
       "1        0        0        1  \n",
       "2        0        0        2  \n",
       "3       11       10        3  \n",
       "4        0        0        3  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame_3users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'vk.com': (1, 3),\n",
       " 'oracle.com': (2, 8),\n",
       " 'geo.mozilla.org': (3, 1),\n",
       " 'google.com': (4, 9),\n",
       " 'accounts.google.com': (5, 1),\n",
       " 'mail.google.com': (6, 2),\n",
       " 'apis.google.com': (7, 1),\n",
       " 'plus.google.com': (8, 1),\n",
       " 'football.kulichki.ru': (9, 2),\n",
       " 'meduza.io': (10, 3),\n",
       " 'yandex.ru': (11, 1)}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frequencies_3users"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Примените полученную функцию к данным по 10 пользователям."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_10users, frequencies_10users = prepare_train_set(Path('10users'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>site_01</th>\n",
       "      <th>site_02</th>\n",
       "      <th>site_03</th>\n",
       "      <th>site_04</th>\n",
       "      <th>site_05</th>\n",
       "      <th>site_06</th>\n",
       "      <th>site_07</th>\n",
       "      <th>site_08</th>\n",
       "      <th>site_09</th>\n",
       "      <th>site_10</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "      <td>6</td>\n",
       "      <td>17</td>\n",
       "      <td>18</td>\n",
       "      <td>14</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19</td>\n",
       "      <td>20</td>\n",
       "      <td>19</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>21</td>\n",
       "      <td>22</td>\n",
       "      <td>23</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "      <td>25</td>\n",
       "      <td>26</td>\n",
       "      <td>27</td>\n",
       "      <td>28</td>\n",
       "      <td>29</td>\n",
       "      <td>30</td>\n",
       "      <td>29</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   site_01  site_02  site_03  site_04  site_05  site_06  site_07  site_08  \\\n",
       "0        1        2        3        4        3        3        4        3   \n",
       "1        6        7        8        9        3       10       11       12   \n",
       "2       14        4       14       14       15       16        6       17   \n",
       "3       19       20       19       14       14       14       14       21   \n",
       "4       24       14       15       25       26       27       28       29   \n",
       "\n",
       "   site_09  site_10  user_id  \n",
       "0        5        3       31  \n",
       "1       13       14       31  \n",
       "2       18       14       31  \n",
       "3       22       23       31  \n",
       "4       30       29       31  "
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame_10users.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вопрос 1. Сколько уникальных сессий из 10 сайтов в выборке с 10 пользователями?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_answer(name: str, value: Any):\n",
    "    with open(f'{name}.txt', 'wt') as fp:\n",
    "        fp.write(str(value))\n",
    "    return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14061"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "write_answer('answer1_1', len(frame_10users))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вопрос 2. Сколько всего уникальных сайтов в выборке из 10 пользователей?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4913"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "write_answer('answer1_2', len(frequencies_10users))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Примените полученную функцию к данным по 150 пользователям."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_150users, frequencies_150users = prepare_train_set(Path('150users'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вопрос 3. Сколько уникальных сессий из 10 сайтов в выборке с 150 пользователями?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "137019"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "write_answer('answer1_3', len(frame_150users))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вопрос 4. Сколько всего уникальных сайтов в выборке из 150 пользователей?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27797"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "write_answer('answer1_4', len(frequencies_150users))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вопрос 5. Каковы топ-10 самых популярных сайтов среди посещенных 150 пользователями?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer1_5_partial = sorted([\n",
    "    (frequency, site)\n",
    "    for site, (_, frequency) in frequencies_150users.items()\n",
    "], reverse=True)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'www.google.fr www.google.com www.facebook.com apis.google.com s.youtube.com clients1.google.com mail.google.com plus.google.com safebrowsing-cache.google.com www.youtube.com'"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "write_answer('answer1_5', ' '.join(site for _, site in answer1_5_partial))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Часть 2. Работа с разреженным форматом данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_train_set_2(\n",
    "    path: Path, \n",
    "    session_length: int = 10,\n",
    "    field_names: List[str] = None,\n",
    "    delimiter: str = ',',\n",
    ") -> Tuple[csr_matrix, numpy.ndarray]:\n",
    "    user_sessions: List[Tuple[int, Counter]] = [\n",
    "        (int(csv_path.stem[-4:]), Counter(session))\n",
    "        for csv_path in sorted(path.glob('*.csv'))\n",
    "        for session in chunked((\n",
    "            row['site']\n",
    "            for row in csv.DictReader(csv_path.open('rt'), fieldnames=field_names, delimiter=delimiter)\n",
    "        ), session_length)\n",
    "    ]\n",
    "    \n",
    "    # Assign an incremental ID to each unique site.\n",
    "    site_ids: Dict[str, int] = dict(zip(set(chain.from_iterable(session for _, session in user_sessions)), count()))\n",
    "        \n",
    "    x = csr_matrix((\n",
    "        [value for _, session in user_sessions for value in session.values()],  # values are visit counts\n",
    "        (\n",
    "            [i for i, (_, session) in enumerate(user_sessions) for value in session.values()],  # row indices are session numbers\n",
    "            [site_ids[site] for _, session in user_sessions for site in session],  # column indices are site IDs\n",
    "        ),\n",
    "    ))\n",
    "    y = numpy.array([user_id for user_id, _ in user_sessions])\n",
    "    \n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[1, 1, 1, 0, 1, 1, 0, 3, 1, 0, 1],\n",
       "        [1, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0],\n",
       "        [1, 0, 0, 0, 0, 0, 2, 2, 0, 0, 0],\n",
       "        [0, 0, 0, 1, 0, 0, 0, 2, 4, 2, 1],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0]], dtype=int64)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_3users, y_3users = prepare_train_set_2(Path('3users'))\n",
    "x_3users.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 696 ms, sys: 14.2 ms, total: 710 ms\n",
      "Wall time: 714 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "x_10users, y_10users = prepare_train_set_2(Path('10users'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('x_10users.pkl', 'wb') as fp:\n",
    "    pickle.dump(x_10users, fp)\n",
    "with open('y_10users.pkl', 'wb') as fp:\n",
    "    pickle.dump(y_10users, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.62 s, sys: 132 ms, total: 6.75 s\n",
      "Wall time: 6.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "x_150users, y_150users = prepare_train_set_2(Path('150users'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('x_150users.pkl', 'wb') as fp:\n",
    "    pickle.dump(x_150users, fp)\n",
    "with open('y_150users.pkl', 'wb') as fp:\n",
    "    pickle.dump(y_150users, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 21.7 s, sys: 1.04 s, total: 22.7 s\n",
      "Wall time: 23.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "x_allcats, y_allcats = prepare_train_set_2(Path('allcats'), field_names=['user_id', 'ts', 'site'], delimiter=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('x_allcats.pkl', 'wb') as fp:\n",
    "    pickle.dump(x_allcats, fp)\n",
    "with open('y_allcats.pkl', 'wb') as fp:\n",
    "    pickle.dump(y_allcats, fp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
