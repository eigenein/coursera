{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Неделя 6. Vowpal Wabbit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPython 3.7.2\n",
      "IPython 7.2.0\n",
      "\n",
      "numpy 1.15.4\n",
      "scipy 1.2.0\n",
      "pandas 0.23.4\n",
      "matplotlib 3.0.2\n",
      "statsmodels 0.9.0\n",
      "sklearn 0.20.2\n",
      "seaborn 0.9.0\n",
      "tqdm 4.31.1\n",
      "\n",
      "compiler   : Clang 6.0 (clang-600.0.57)\n",
      "system     : Darwin\n",
      "release    : 18.5.0\n",
      "machine    : x86_64\n",
      "processor  : i386\n",
      "CPU cores  : 12\n",
      "interpreter: 64bit\n",
      "Git hash   : 4c199e294683fb314d8a888496ab119eb1bf765a\n"
     ]
    }
   ],
   "source": [
    "%reload_ext watermark\n",
    "%watermark -v -m -p numpy,scipy,pandas,matplotlib,statsmodels,sklearn,seaborn,tqdm -g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy\n",
    "import pandas\n",
    "from pandas import DataFrame, read_csv\n",
    "from scipy.sparse import csr_matrix, vstack\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tqdm import tqdm_notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. Подготовка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Далее посмотрим на Vowpal Wabbit в деле. Правда, в задаче нашего соревнования при бинарной классификации веб-сессий мы разницы не заметим – как по качеству, так и по скорости работы (хотя можете проверить), продемонстрируем всю резвость VW в задаче классификации на 400 классов. Исходные данные все те же самые, но выделено 400 пользователей, и решается задача их идентификации. Скачайте данные [отсюда](https://inclass.kaggle.com/c/identify-me-if-you-can4/data) – файлы `train_sessions_400users.csv` и `test_sessions_400users.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sites = [f'site{i}' for i in range(1, 11)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = read_csv('train_sessions_400users.csv', index_col='session_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = read_csv('test_sessions_400users.csv', index_col='session_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((182793, 21), (46473, 20), 400)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape, test.shape, train['user_id'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vowpal Wabbit любит, чтоб метки классов были распределены от 1 до K, где K – число классов в задаче классификации (в нашем случае – 400). Поэтому придется применить `LabelEncoder`, да еще и +1 потом добавить (`LabelEncoder` переводит метки в диапозон от 0 до K-1). Потом надо будет применить обратное преобразование."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train['user_id']\n",
    "y_encoder = LabelEncoder()\n",
    "y_vw = y_encoder.fit_transform(y) + 1\n",
    "\n",
    "train = train[sites].fillna(0).astype(numpy.int)\n",
    "test = test[sites].fillna(0).astype(numpy.int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Далее будем сравнивать VW с `SGDClassifier` и с логистической регрессией. Всем моделям этим нужна предобработка входных данных. Подготовьте для sklearn-моделей разреженные матрицы, как мы это делали в 5 части:\n",
    "\n",
    "- объедините обучающиую и тестовую выборки\n",
    "- выберите только сайты (признаки от `site1` до `site10`)\n",
    "- замените пропуски на нули (сайты у нас нумеровались с 0)\n",
    "- переведите в разреженный формат `csr_matrix`\n",
    "- разбейте обратно на обучающую и тестовую части"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_test = pandas.concat([train, test], sort=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57521312a6404f859b1476c375019b9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "n_cols = X_train_test.values.max()  # максимальный индекс сайта\n",
    "X_train_test_sparse = vstack([\n",
    "    csr_matrix((\n",
    "        [value for value in counter.values()],  # data: числа визитов\n",
    "        [key for key, value in counter.items()],  # indices: индексы сайтов\n",
    "        [0, len(counter)],  # indptr: 0...число ненулевых элементов\n",
    "    ), shape=(1, n_cols))\n",
    "    for counter in tqdm_notebook(\n",
    "        Counter(filter(None, row))  # подсчитываем число визитов каждого сайта в сессии, отфильтровываем нули\n",
    "        for row in X_train_test.itertuples(index=False)  # ходим по всем сессиям\n",
    "    )\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_sparse = X_train_test_sparse[:len(train), :]\n",
    "X_test_sparse = X_train_test_sparse[len(train):, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. Валидация по отложенной выборке"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выделим обучающую (70%) и отложенную (30%) части исходной обучающей выборки. Данные не перемешиваем, учитываем, что сессии отсортированы по времени."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "share = int(0.7 * train.shape[0])\n",
    "train_part = train[sites].iloc[:share, :]\n",
    "valid = train[sites].iloc[share:, :]\n",
    "X_train_part_sparse = X_train_sparse[:share, :]\n",
    "X_valid_sparse = X_train_sparse[share:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_part = y[:share]\n",
    "y_valid = y[share:]\n",
    "y_train_part_vw = y_vw[:share]\n",
    "y_valid_vw = y_vw[share:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реализуйте функцию, `arrays_to_vw`, переводящую обучающую выборку в формат Vowpal Wabbit.\n",
    "\n",
    "Вход:\n",
    "\n",
    "- `X` – матрица NumPy (обучающая выборка)\n",
    "- `y` (необяз.) - вектор ответов (NumPy). Необязателен, поскольку тестовую матрицу будем обрабатывать этой же функцией\n",
    "- `train` – флаг, `True` в случае обучающей выборки, `False` – в случае тестовой выборки\n",
    "- `out_file` – путь к файлу `.vw`, в который будет произведена запись\n",
    "\n",
    "Детали:\n",
    "\n",
    "- надо пройтись по всем строкам матрицы `X` и записать через пробел все значения, предварительно добавив вперед нужную метку класса из вектора `y` и знак-разделитель `|`\n",
    "- в тестовой выборке на месте меток целевого класса можно писать произвольные, допустим, 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_vw(x, y, path):\n",
    "    with path.open('wt') as fp:\n",
    "        for row, y_ in zip(x.itertuples(False), y):\n",
    "            print(f'{y_} | {\" \".join(map(str, row))}', file=fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Примените написанную функцию к части обучащей выборки `(train_df_part, y_train_part_for_vw)`, к отложенной выборке `(valid_df, y_valid_for_vw)`, ко всей обучающей выборке и ко всей тестовой выборке. Обратите внимание, что на вход наш метод принимает именно матрицы и вектора NumPy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "262 | 23713 23720 23713 23713 23720 23713 23713 23713 23713 23713\r\n",
      "82 | 8726 8725 665 8727 45 8725 45 5320 5320 5320\r\n",
      "16 | 303 19 303 303 303 303 303 309 303 303\r\n"
     ]
    }
   ],
   "source": [
    "to_vw(train_part, y_train_part_vw, Path('train_part.vw'))\n",
    "!head -3 train_part.vw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 | 7 923 923 923 11 924 7 924 838 7\r\n",
      "160 | 91 198 11 11 302 91 668 311 310 91\r\n",
      "312 | 27085 848 118 118 118 118 11 118 118 118\r\n"
     ]
    }
   ],
   "source": [
    "to_vw(valid, y_valid_vw, Path('valid.vw'))\n",
    "!head -3 valid.vw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 | 9 304 308 307 91 308 312 300 305 309\r\n",
      "1 | 838 504 68 11 838 11 838 886 27 305\r\n",
      "1 | 190 192 8 189 191 189 190 2375 192 8\r\n"
     ]
    }
   ],
   "source": [
    "to_vw(test[sites], numpy.ones((len(test),), dtype=numpy.int), Path('test.vw'))\n",
    "!head -3 test.vw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "262 | 23713 23720 23713 23713 23720 23713 23713 23713 23713 23713\r\n",
      "82 | 8726 8725 665 8727 45 8725 45 5320 5320 5320\r\n",
      "16 | 303 19 303 303 303 303 303 309 303 303\r\n"
     ]
    }
   ],
   "source": [
    "to_vw(train[sites], y_vw, Path('train.vw'))\n",
    "!head -3 train.vw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучите модель Vowpal Wabbit на выборке `train_part.vw`. Укажите, что решается задача классификации с 400 классами (`--oaa`), сделайте 3 прохода по выборке (`--passes`). Задайте некоторый кэш-файл (`--cache_file`, можно просто указать флаг `-c`), так VW будет быстрее делать все следующие после первого проходы по выборке (прошлый кэш-файл удаляется с помощью аргумента `-k`). Также укажите значение параметра `b=26`. Это число бит, используемых для хэширования, в данном случае нужно больше, чем `18` по умолчанию. Наконец, укажите `random_seed=17`. Остальные параметры пока не меняйте, далее уже в свободном режиме соревнования можете попробовать другие функции потерь."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.6.1\r\n"
     ]
    }
   ],
   "source": [
    "!vw --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final_regressor = train_part_regressor.vw\n",
      "Num weight bits = 26\n",
      "learning rate = 0.5\n",
      "initial_t = 0\n",
      "power_t = 0.5\n",
      "decay_learning_rate = 1\n",
      "using cache_file = train_part.cache\n",
      "ignoring text input in favor of cache input\n",
      "num sources = 1\n",
      "average  since         example        example  current  current  current\n",
      "loss     last          counter         weight    label  predict features\n",
      "1.000000 1.000000            1            1.0      262        1       11\n",
      "1.000000 1.000000            2            2.0       82      262       11\n",
      "1.000000 1.000000            4            4.0      241      262       11\n",
      "1.000000 1.000000            8            8.0      352      262       11\n",
      "1.000000 1.000000           16           16.0      135       16       11\n",
      "1.000000 1.000000           32           32.0       71      112       11\n",
      "0.968750 0.937500           64           64.0      358      231       11\n",
      "0.976562 0.984375          128          128.0      348      346       11\n",
      "0.941406 0.906250          256          256.0      202      202       11\n",
      "0.947266 0.953125          512          512.0       30        1       11\n",
      "0.925781 0.904297         1024         1024.0       36      290       11\n",
      "0.908203 0.890625         2048         2048.0       21      128       11\n",
      "0.880127 0.852051         4096         4096.0       80      229       11\n",
      "0.856323 0.832520         8192         8192.0      307      356       11\n",
      "0.828003 0.799683        16384        16384.0       59      193       11\n",
      "0.795441 0.762878        32768        32768.0      262       30       11\n",
      "0.760468 0.725494        65536        65536.0      171      238       11\n",
      "0.724008 0.724008       131072       131072.0        6        6       11 h\n",
      "0.697339 0.670672       262144       262144.0       12       12       11 h\n",
      "\n",
      "finished run\n",
      "number of examples per pass = 115160\n",
      "passes used = 3\n",
      "weighted example sum = 345480.000000\n",
      "weighted label sum = 0.000000\n",
      "average loss = 0.661352 h\n",
      "total feature number = 3800280\n"
     ]
    }
   ],
   "source": [
    "!vw \\\n",
    "    --random_seed 17 \\\n",
    "    --bit_precision 26 \\\n",
    "    --oaa 400 \\\n",
    "    --data train_part.vw \\\n",
    "    --cache_file train_part.cache \\\n",
    "    --passes 3 \\\n",
    "    --final_regressor train_part_regressor.vw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Запишите прогнозы на выборке `valid.vw` в `vw_valid_pred.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "only testing\n",
      "predictions = valid_predictions_vw.csv\n",
      "Num weight bits = 26\n",
      "learning rate = 0.5\n",
      "initial_t = 0\n",
      "power_t = 0.5\n",
      "using no cache\n",
      "Reading datafile = valid.vw\n",
      "num sources = 1\n",
      "average  since         example        example  current  current  current\n",
      "loss     last          counter         weight    label  predict features\n",
      "1.000000 1.000000            1            1.0        4      188       11\n",
      "1.000000 1.000000            2            2.0      160      220       11\n",
      "0.750000 0.500000            4            4.0      143      143       11\n",
      "0.750000 0.750000            8            8.0      247      247       11\n",
      "0.687500 0.625000           16           16.0      341       30       11\n",
      "0.593750 0.500000           32           32.0      237      237       11\n",
      "0.609375 0.625000           64           64.0      178      178       11\n",
      "0.640625 0.671875          128          128.0      132      228       11\n",
      "0.656250 0.671875          256          256.0       14       14       11\n",
      "0.646484 0.636719          512          512.0      370      370       11\n",
      "0.663086 0.679688         1024         1024.0      189      189       11\n",
      "0.655762 0.648438         2048         2048.0      311      311       11\n",
      "0.657227 0.658691         4096         4096.0      195      318       11\n",
      "0.660156 0.663086         8192         8192.0      171      195       11\n",
      "0.657654 0.655151        16384        16384.0      362       51       11\n",
      "0.655121 0.652588        32768        32768.0      248      248       11\n",
      "\n",
      "finished run\n",
      "number of examples = 54838\n",
      "weighted example sum = 54838.000000\n",
      "weighted label sum = 0.000000\n",
      "average loss = 0.654583\n",
      "total feature number = 603218\n",
      "\n",
      "188\n",
      "220\n",
      "364\n"
     ]
    }
   ],
   "source": [
    "!vw \\\n",
    "    --initial_regressor train_part_regressor.vw \\\n",
    "    --testonly \\\n",
    "    --data valid.vw \\\n",
    "    --predictions valid_predictions_vw.csv\n",
    "!echo\n",
    "!head -3 valid_predictions_vw.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Считайте прогнозы `kaggle_data/vw_valid_pred.csv` из файла и посмотрите на долю правильных ответов на отложенной части.\n",
    "\n",
    "**Вопрос 1.** Посчитайте долю правильных ответов на отложенной выборке для Vowpal Wabbit, округлите до 3 знаков после запятой."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.345"
     ]
    }
   ],
   "source": [
    "answer6_1 = accuracy_score(y_valid_vw, read_csv(\"valid_predictions_vw.csv\", header=None))\n",
    "Path('answer6_1.txt').write_text(f'{answer6_1:.3f}')\n",
    "!cat answer6_1.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь обучите `SGDClassifier` (3 прохода по выборке, логистическая функция потерь) и `LogisticRegression` на 70% разреженной обучающей выборки – `(X_train_part_sparse, y_train_part)`, сделайте прогноз для отложенной выборки `(X_valid_sparse, y_valid)` и посчитайте доли верных ответов. Логистическая регрессия будет обучаться не быстро (у меня – 4 минуты) – это нормально. Укажите везде `random_state=17, n_jobs=-1`. Для `SGDClassifier` также укажите `max_iter=3`.\n",
    "\n",
    "**Вопрос 2.** Посчитайте долю правильных ответов на отложенной выборке для SGD, округлите до 3 знаков после запятой."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/eigenein/GitHub/mipt-ya-ml-spec/venv/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.291"
     ]
    }
   ],
   "source": [
    "sgd = SGDClassifier(random_state=17, n_jobs=-1, max_iter=3, tol=None, loss='log')\n",
    "answer6_2 = accuracy_score(\n",
    "    y_valid,\n",
    "    sgd.fit(X_train_part_sparse, y_train_part).predict(X_valid_sparse),\n",
    ")\n",
    "Path('answer6_2.txt').write_text(f'{answer6_2:.3f}')\n",
    "!cat answer6_2.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вопрос 3.** Посчитайте долю правильных ответов на отложенной выборке для логистической регрессии, округлите до 3 знаков после запятой."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/eigenein/GitHub/mipt-ya-ml-spec/venv/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/eigenein/GitHub/mipt-ya-ml-spec/venv/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/Users/eigenein/GitHub/mipt-ya-ml-spec/venv/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1300: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]0.363\n",
      "CPU times: user 19min 8s, sys: 1.87 s, total: 19min 9s\n",
      "Wall time: 19min 10s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "lr = LogisticRegression(random_state=17, verbose=3, multi_class='multinomial')\n",
    "answer6_3 = accuracy_score(\n",
    "    y_valid,\n",
    "    lr.fit(X_train_part_sparse, y_train_part).predict(X_valid_sparse),\n",
    ")\n",
    "Path('answer6_3.txt').write_text(f'{answer6_3:.3f}')\n",
    "!cat answer6_3.txt\n",
    "!echo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3. Валидация по тестовой выборке (Public Leaderboard)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучите модель VW с теми же параметрами на всей обучающей выборке – `train.vw`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final_regressor = train_regressor.vw\n",
      "Num weight bits = 26\n",
      "learning rate = 0.5\n",
      "initial_t = 0\n",
      "power_t = 0.5\n",
      "decay_learning_rate = 1\n",
      "creating cache_file = train.cache\n",
      "Reading datafile = train.vw\n",
      "num sources = 1\n",
      "average  since         example        example  current  current  current\n",
      "loss     last          counter         weight    label  predict features\n",
      "1.000000 1.000000            1            1.0      262        1       11\n",
      "1.000000 1.000000            2            2.0       82      262       11\n",
      "1.000000 1.000000            4            4.0      241      262       11\n",
      "1.000000 1.000000            8            8.0      352      262       11\n",
      "1.000000 1.000000           16           16.0      135       16       11\n",
      "1.000000 1.000000           32           32.0       71      112       11\n",
      "0.968750 0.937500           64           64.0      358      231       11\n",
      "0.976562 0.984375          128          128.0      348      346       11\n",
      "0.941406 0.906250          256          256.0      202      202       11\n",
      "0.947266 0.953125          512          512.0       30        1       11\n",
      "0.925781 0.904297         1024         1024.0       36      290       11\n",
      "0.908203 0.890625         2048         2048.0       21      128       11\n",
      "0.880127 0.852051         4096         4096.0       80      229       11\n",
      "0.856323 0.832520         8192         8192.0      307      356       11\n",
      "0.828003 0.799683        16384        16384.0       59      193       11\n",
      "0.795441 0.762878        32768        32768.0      262       30       11\n",
      "0.760468 0.725494        65536        65536.0      171      238       11\n",
      "0.725319 0.690170       131072       131072.0      180      159       11\n",
      "0.692989 0.692989       262144       262144.0       88      221       11 h\n",
      "\n",
      "finished run\n",
      "number of examples per pass = 164514\n",
      "passes used = 3\n",
      "weighted example sum = 493542.000000\n",
      "weighted label sum = 0.000000\n",
      "average loss = 0.642595 h\n",
      "total feature number = 5428962\n"
     ]
    }
   ],
   "source": [
    "!vw \\\n",
    "    --random_seed 17 \\\n",
    "    --bit_precision 26 \\\n",
    "    --oaa 400 \\\n",
    "    --data train.vw \\\n",
    "    --cache_file train.cache \\\n",
    "    --passes 3 \\\n",
    "    --final_regressor train_regressor.vw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сделайте прогноз для тестовой выборки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "only testing\n",
      "predictions = test_predictions_vw.csv\n",
      "Num weight bits = 26\n",
      "learning rate = 0.5\n",
      "initial_t = 0\n",
      "power_t = 0.5\n",
      "using no cache\n",
      "Reading datafile = test.vw\n",
      "num sources = 1\n",
      "average  since         example        example  current  current  current\n",
      "loss     last          counter         weight    label  predict features\n",
      "1.000000 1.000000            1            1.0        1       90       11\n",
      "1.000000 1.000000            2            2.0        1       21       11\n",
      "1.000000 1.000000            4            4.0        1      265       11\n",
      "1.000000 1.000000            8            8.0        1      137       11\n",
      "1.000000 1.000000           16           16.0        1      273       11\n",
      "1.000000 1.000000           32           32.0        1      384       11\n",
      "1.000000 1.000000           64           64.0        1      139       11\n",
      "1.000000 1.000000          128          128.0        1       85       11\n",
      "1.000000 1.000000          256          256.0        1       25       11\n",
      "0.994141 0.988281          512          512.0        1      364       11\n",
      "0.990234 0.986328         1024         1024.0        1      202       11\n",
      "0.992188 0.994141         2048         2048.0        1      181       11\n",
      "0.993652 0.995117         4096         4096.0        1       21       11\n",
      "0.994629 0.995605         8192         8192.0        1      137       11\n",
      "0.995300 0.995972        16384        16384.0        1      326       11\n",
      "0.994568 0.993835        32768        32768.0        1       10       11\n",
      "\n",
      "finished run\n",
      "number of examples = 46473\n",
      "weighted example sum = 46473.000000\n",
      "weighted label sum = 0.000000\n",
      "average loss = 0.994642\n",
      "total feature number = 511203\n",
      "\n",
      "90\n",
      "21\n",
      "311\n"
     ]
    }
   ],
   "source": [
    "!vw \\\n",
    "    --initial_regressor train_regressor.vw \\\n",
    "    --testonly \\\n",
    "    --data test.vw \\\n",
    "    --predictions test_predictions_vw.csv\n",
    "!echo\n",
    "!head -3 test_predictions_vw.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Запишите прогноз в файл, примените обратное преобразование меток (был `LabelEncoder` и потом +1 в меткам) и отправьте решение на Kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_answer(y_test: numpy.ndarray, name: str):\n",
    "    pandas \\\n",
    "        .DataFrame(\n",
    "            y_encoder.inverse_transform(y_test - 1),\n",
    "            index=numpy.arange(1, y_test.shape[0] + 1),\n",
    "            columns=['user_id'],\n",
    "        ) \\\n",
    "        .to_csv(name, index_label='session_id', float_format='%f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "session_id,user_id\r\n",
      "1,224\r\n",
      "2,48\r\n"
     ]
    }
   ],
   "source": [
    "write_answer(read_csv('test_predictions_vw.csv', header=None).values.reshape(-1), 'test_predictions_vw_kaggle.csv')\n",
    "!head -3 test_predictions_vw_kaggle.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вопрос 4.** Какова доля правильных ответов на публичной части тестовой выборки (public leaderboard) для Vowpal Wabbit?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "Path('answer6_4.txt').write_text('0.18768');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вопрос 5.** Какова доля правильных ответов на публичной части тестовой выборки (public leaderboard) для SGD?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "session_id,user_id\r\n",
      "1,50\r\n",
      "2,149\r\n"
     ]
    }
   ],
   "source": [
    "pandas \\\n",
    "    .DataFrame(\n",
    "        sgd.fit(X_train_part_sparse, y_train_part).predict(X_test_sparse),\n",
    "        index=numpy.arange(1, X_test_sparse.shape[0] + 1),\n",
    "        columns=['user_id'],\n",
    "    ) \\\n",
    "    .to_csv('test_predictions_sgd_kaggle.csv', index_label='session_id', float_format='%f')\n",
    "!head -3 test_predictions_sgd_kaggle.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "Path('answer6_5.txt').write_text('0.17855');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вопрос 6.** Какова доля правильных ответов на публичной части тестовой выборки (public leaderboard) для логистической регрессии?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/eigenein/GitHub/mipt-ya-ml-spec/venv/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/eigenein/GitHub/mipt-ya-ml-spec/venv/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/Users/eigenein/GitHub/mipt-ya-ml-spec/venv/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1300: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]session_id,user_id\n",
      "1,255\n",
      "2,149\n"
     ]
    }
   ],
   "source": [
    "pandas \\\n",
    "    .DataFrame(\n",
    "        lr.fit(X_train_sparse, y).predict(X_test_sparse),\n",
    "        index=numpy.arange(1, X_test_sparse.shape[0] + 1),\n",
    "        columns=['user_id'],\n",
    "    ) \\\n",
    "    .to_csv('test_predictions_lr_kaggle.csv', index_label='session_id', float_format='%f')\n",
    "!head -3 test_predictions_lr_kaggle.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "Path('answer6_6.txt').write_text('0.19891');"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
